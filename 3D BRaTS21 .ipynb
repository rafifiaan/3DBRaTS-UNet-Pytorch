{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ead93c",
   "metadata": {},
   "source": [
    "### Setup Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a566191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nibabel in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from nibabel) (1.24.3)\n",
      "Requirement already satisfied: packaging>=17 in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from nibabel) (23.0)\n",
      "Requirement already satisfied: glob2 in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (0.7)\n",
      "Requirement already satisfied: monai in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from monai) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.9 in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from monai) (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from torch>=1.9->monai) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from torch>=1.9->monai) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from torch>=1.9->monai) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from torch>=1.9->monai) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from torch>=1.9->monai) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from torch>=1.9->monai) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.9->monai) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rafi aliefian\\anaconda3\\lib\\site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nibabel \n",
    "!pip install glob2\n",
    "!pip install monai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe0fa7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Setup Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c11c283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAFI ALIEFIAN\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch.utils import data as torch_data\n",
    "import monai.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c04d2",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n",
    "Pairing & Classification Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85593645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths = './training_data'\n",
    "path = glob.glob(paths+'/*')\n",
    "arrays = []\n",
    "segmen = []\n",
    "types = [\"flair\", \"t1\", \"t1ce\",\"t2\"]\n",
    "max_dir = 30\n",
    "\n",
    "for idx, a in enumerate(path):\n",
    "    if idx >= max_dir:\n",
    "        break\n",
    "    trainData = glob.glob(a+'/*') \n",
    "    for modality in trainData:\n",
    "        strsplit = modality.split('_')\n",
    "        typefiles = strsplit[4].split('.')[0]\n",
    "        if typefiles in types:\n",
    "            nifti_file = nib.load(modality)\n",
    "            brain_affine = nifti_file.affine  \n",
    "            brain_numpy = np.asarray(nifti_file.dataobj)\n",
    "            dataPad = np.pad(brain_numpy, ((8,8), (8,8), (50,51)), 'constant')\n",
    "            dataPad = dataPad/np.max(dataPad)\n",
    "            arrays.append(dataPad)\n",
    "        else:\n",
    "            nifti_file = nib.load(modality)\n",
    "            brain_affine = nifti_file.affine\n",
    "            brain_numpy = np.asarray(nifti_file.dataobj)\n",
    "            dataPad = np.pad(brain_numpy, ((8,8), (8,8), (50,51)), 'constant')\n",
    "            dataPad = dataPad/np.max(dataPad)\n",
    "            segmen.append(dataPad)\n",
    "\n",
    "    newDataArrays = nib.Nifti1Image(np.asarray(arrays), nifti_file.affine, nifti_file.header)\n",
    "    nib.save(newDataArrays, './train/BraTS2021_'+ a.split('_')[2] + '.nii')\n",
    "\n",
    "    newDataSegmen = nib.Nifti1Image(np.asarray(segmen), nifti_file.affine, nifti_file.header)\n",
    "    nib.save(newDataSegmen, './label/BraTS2021_'+ a.split('_')[2] + '.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a928b90",
   "metadata": {},
   "source": [
    "### Visualize Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca19dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest = './training_data/BraTS2021_00495/BraTS2021_00495_t1.nii.gz'\n",
    "img1 = nib.load(dataTest)\n",
    "np.shape(img1.dataobj)\n",
    "plt.imshow(img1.dataobj[:,:,145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16411043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest = './train/BraTS2021_00495.nii'\n",
    "img2 = nib.load(dataTest)\n",
    "np.shape(img2.dataobj)\n",
    "plt.imshow(img2.dataobj[1,:,:,195])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc19e2",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a007ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = sorted(glob.glob('./train/*'))\n",
    "label_train = sorted(glob.glob('./label/*'))\n",
    "\n",
    "trainDict = [\n",
    "    {\n",
    "        \"images\": image_trains,\n",
    "        \"label\": label_trains,\n",
    "    } for image_trains, label_trains in zip(image_train, label_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee1040d",
   "metadata": {},
   "source": [
    "### Datasets Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12612f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadNifti(path):\n",
    "    img_train = nib.load(path)\n",
    "    all_img = img_train.affine  \n",
    "    brain_numpy = np.asarray(img_train.dataobj)\n",
    "    return brain_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0385230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetsMRI(torch_data.Dataset):\n",
    "    def __init__(self, data_root, transform=None):\n",
    "        super(DatasetsMRI, self).__init__()\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_root)\n",
    "    \n",
    "    def __getitem__(self, index:int) -> tuple:\n",
    "        images_label = self.data_root[index]\n",
    "        img1 = LoadNifti(images_label['images'])\n",
    "        img2 = LoadNifti(images_label['label'])\n",
    "        itemDict = ({\n",
    "               \"images\": img1,\n",
    "                \"label\": img2 \n",
    "        }) \n",
    "        if self.transform:\n",
    "            itemDict = self.transform({'images':img1, 'label':img2})\n",
    "        return itemDict['images'], itemDict['label'], index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d56a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDatasets = DatasetsMRI(trainDict)\n",
    "trainDatasets = DatasetsMRI(trainDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2c08e",
   "metadata": {},
   "source": [
    "### Class Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "img,lbl,idx = testDatasets[0]\n",
    "print(np.shape(img))\n",
    "plt.imshow(img[0, :, :, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28170143",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4956479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transform():\n",
    "    \n",
    "    data_aug = [\n",
    "        # crop\n",
    "        \n",
    "\n",
    "        # spatial aug\n",
    "#         transforms.RandFlipd(keys=\"images\", prob=1, spatial_axis=0),\n",
    "#         transforms.RandFlipd(keys=\"images\", prob=1, spatial_axis=1),\n",
    "#         transforms.RandFlipd(keys=\"images\", prob=1, spatial_axis=2),\n",
    "\n",
    "        # intensity aug\n",
    "        #transforms.RandGaussianNoised(keys='image', prob=0.15, mean=0.0, std=0.2),\n",
    "        transforms.RandGaussianSmoothd(\n",
    "            keys='images', prob=0.3, sigma_x=(0.5, 1.5), sigma_y=(0.5, 1.5), sigma_z=(0.5, 1.5)),\n",
    "        #transforms.RandAdjustContrastd(keys='image', prob=0.15, gamma=(0.7, 1.3)),\n",
    "\n",
    "        # other stuff\n",
    "        transforms.EnsureTyped(keys=[\"images\", 'label']),\n",
    "    ]\n",
    "    return transforms.Compose(data_aug)\n",
    "def test_transform():\n",
    "    \n",
    "    infer_transform = [transforms.EnsureTyped(keys=[\"images\", 'label'])]\n",
    "    return transforms.Compose(infer_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loader(case_names):\n",
    "    train_transforms = train_transform()\n",
    "    train_dataset = DatasetsMRI(\n",
    "        data_root=case_names, \n",
    "        transform=train_transforms)\n",
    "\n",
    "    return DataLoader(train_dataset, batch_size=1, shuffle=True, \n",
    "                       num_workers=1, pin_memory=True)\n",
    "\n",
    "def get_test_loader(case_names):\n",
    "    test_transforms = test_transform()\n",
    "    test_dataset = DatasetsMRI(\n",
    "        data_root=case_names, \n",
    "        transform=test_transforms)\n",
    "\n",
    "    return DataLoader(test_dataset, batch_size=1, shuffle=False, \n",
    "                    num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2909818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(trainDict)\n",
    "test_size = int(0.3 * dataset_size)\n",
    "train_size = dataset_size - test_size\n",
    "train_dataset , test_dataset = torch.utils.data.random_split(trainDict,[train_size,test_size])\n",
    "train_loader = get_train_loader(train_dataset)\n",
    "test_loader = get_test_loader(test_dataset)\n",
    "print(test_size)\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e510e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test use RandFlip\n",
    "train_dataset = DatasetsMRI(\n",
    "        data_root=trainDict, \n",
    "        transform=train_transform())\n",
    "img,lbl,idx = train_dataset[0]\n",
    "print(np.shape(img))\n",
    "plt.imshow(img[0, :, 100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test unused RandFlip\n",
    "train_dataset = DatasetsMRI(\n",
    "        data_root=trainDict, \n",
    "        transform=train_transform())\n",
    "img,lbl,idx = train_dataset[0]\n",
    "print(np.shape(img))\n",
    "plt.imshow(img[0, :, 100, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b844b78",
   "metadata": {},
   "source": [
    "### Other Code (unpairing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = n2_img.get_fdata().astype(np.float32) / n2_img.get_fdata().max()\n",
    "print(normalized.shape)\n",
    "print(np.max(normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one image from DecathlonDataset to visualize and check the 4 channels\n",
    "val_data_example = val_ds[2]\n",
    "print(f\"image shape: {val_data_example['image'].shape}\")\n",
    "plt.figure(\"image\", (24, 6))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.title(f\"image channel {i}\")\n",
    "    plt.imshow(val_data_example[\"image\"][i, :, :, 60].detach().cpu(), cmap=\"gray\")\n",
    "plt.show()\n",
    "# also visualize the 3 channels label corresponding to this image\n",
    "print(f\"label shape: {val_data_example['label'].shape}\")\n",
    "plt.figure(\"label\", (18, 6))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.title(f\"label channel {i}\")\n",
    "    plt.imshow(val_data_example[\"label\"][i, :, :, 60].detach().cpu())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
